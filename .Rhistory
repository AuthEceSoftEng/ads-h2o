#' Ensure that .libpaths of Rscript.exe and R.exe agree
if(length(.libPaths()) == 1){
# We're in Rscript.exe
possible_lib_paths <- file.path(Sys.getenv(c('USERPROFILE','R_USER')),
"R","win-library",
paste(R.version$major,
substr(R.version$minor,1,1),
sep='.'))
indx <- which(file.exists(possible_lib_paths))
if(length(indx)){
.libPaths(possible_lib_paths[indx[1]])
}
# CLEAN UP
rm(indx,possible_lib_paths)
}
#' Ensure that .libpaths of Rscript.exe and R.exe agree
if(length(.libPaths()) == 1){
# We're in Rscript.exe
possible_lib_paths <- file.path(Sys.getenv(c('USERPROFILE','R_USER')),
"R","win-library",
paste(R.version$major,
substr(R.version$minor,1,1),
sep='.'))
indx <- which(file.exists(possible_lib_paths))
if(length(indx)){
.libPaths(possible_lib_paths[indx[1]])
}
# CLEAN UP
rm(indx,possible_lib_paths)
}
#' The script for running an experiment. This is the interface of automl software. It offfers the functionalities of
#' training the system, performing an experiment for a particular dataset by defining appropriate flags.
#' It sources build_script.R to set up the workspace. <br> <br> <br>
#' Ensure that .libpaths of Rscript.exe and R.exe agree
if(length(.libPaths()) == 1){
# We're in Rscript.exe
possible_lib_paths <- file.path(Sys.getenv(c('USERPROFILE','R_USER')),
"R","win-library",
paste(R.version$major,
substr(R.version$minor,1,1),
sep='.'))
indx <- which(file.exists(possible_lib_paths))
if(length(indx)){
.libPaths(possible_lib_paths[indx[1]])
}
# CLEAN UP
rm(indx,possible_lib_paths)
}
#' Set up workspace
source("build_script.R")
#' Load user's configuration
#' Define command-line options
option_list <- list(
make_option( c("-d", "--dataset"), type = "character",
default = "baboon_mating.csv", help = "dataset file name",
metavar = "character"),
make_option( c("-p", "--project"), type = "character", help = "name of new project",
default = NULL, metavar = "character"),
make_option( c("-w", "--workspace"), type = "character",
default = workspace_dir, help = "name of workspace directory",
metavar = "character"),
make_option( c("-t", "--train"), action = "store_true", dest = "train"),
make_option( c("-e", "--experiment"), action = "store_false", dest = "train"),
make_option( c("-c", "--compare"), action = "store_true", dest = "compare", default = FALSE)
);
opt_parser <- OptionParser(option_list=option_list);
opt        <- parse_args(opt_parser);
#' Call InputParser
inputparser <- new('InputParser')
inputparser$parseCommand(options = opt)
#' A script that sets up automl's workspace. It installs missing packages and sources the files.
#' Run with `source("build_script.R")` from automl directory. <br> <br> <br>
#' Install and load missing  packages
library_path <- "lib"
.libPaths(c( .libPaths(),library_path))
dir.create(library_path,showWarnings = FALSE)
repos_path <- "http://cran.rstudio.com/"
if(!require(nnet))
{
print("You are missing the package 'nnet', we will now try to install it...")
install.packages("nnet", repos = repos_path, lib = library_path)
library(nnet)
}
if(!require(ROCR))
{
print("You are missing the package 'ROCR', we will now try to install it...")
install.packages("ROCR", repos = repos_path, lib = library_path)
library(ROCR)
}
if(!require(plot3D))
{
print("You are missing the package 'plot3D', we will now try to install it...")
install.packages("plot3D", repos = repos_path, lib = library_path)
library(plot3D)
}
if(!require(akima))
{
print("You are missing the package 'akima', we will now try to install it...")
install.packages("akima", repos = repos_path, lib = library_path)
library(akima)
}
if(!require(fields))
{
print("You are missing the package 'fields', we will now try to install it...")
install.packages("fields", repos = repos_path, lib = library_path)
library(fields)
}
if(!require(ggplot2))
{
print("You are missing the package 'ggpllot2', we will now try to install it...")
install.packages("ggplot2", repos = repos_path, lib = library_path)
library(ggplot2)
}
if(!require(plyr))
{
print("You are missing the package 'plyr', we will now try to install it...")
install.packages("plyr", repos = repos_path, lib = library_path)
library(plyr)
}
if(!require(ranger))
{
print("You are missing the package 'ranger', we will now try to install it...")
install.packages("ranger", repos = repos_path, lib = library_path)
library(ranger)
}
if(!require(optparse))
{
print("You are missing the package 'optparse', we will now try to install it...")
install.packages("optparse", repos = repos_path, lib = library_path)
library(optparse)
}
if(!require(randomForest))
{
print("You are missing the package 'randomForest', we will now try to install it...")
install.packages("randomForest", repos = repos_path, lib = library_path)
library(randomForest)
}
if(!require(doParallel))
{
print("You are missing the package 'doParallel', we will now try to install it...")
install.packages("doParallel", repos = repos_path , lib = library_path)
library(doParallel)
}
if(!require(foreach))
{
print("You are missing the package 'foreach', we will now try to install it...")
install.packages("foreach", repos = repos_path, lib = library_path)
library(foreach)
}
if(!require(methods))
{
print("You are missing the package 'methods', we will now try to install it...")
install.packages("methods", repos = repos_path, lib = library_path)
library(methods)
}
if(!require(caret))
{
print("You are missing the package 'caret', we will now try to install it...")
install.packages("caret", dependencies = TRUE, repos = repos_path, lib = library_path)
library(caret)
}
if(!require(FactoMineR))
{
print("You are missing the package 'FactoMineR', we will now try to install it...")
install.packages("FactoMineR", repos = repos_path, lib = library_path)
library(FactoMineR)
}
if(!require(MASS))
{
print("You are missing the package 'MASS', we will now try to install it...")
install.packages("MASS", repos = repos_path, lib = library_path)
library(MASS)
}
if(!require(coin))
{
print("You are missing the package 'coin', we will now try to install it...")
install.packages("coin", repos = repos_path, lib = library_path)
library(coin)
}
if(!require(multcomp))
{
print("You are missing the package 'multcomp', we will now try to install it...")
install.packages("multcomp", repos = repos_path, lib = library_path)
library(multcomp)
}
if(!require(colorspace))
{
print("You are missing the package 'colorspace', we will now try to install it...")
install.packages("colorspace", repos = repos_path, lib ="/home/elennisioti/thesis_ws/lib")
library(colorspace)
}
if(!require(pROC))
{
print("You are missing the package 'pROC', we will now try to install it...")
install.packages("pROC", repos = repos_path, lib = library_path)
library(pROC)
}
if(!require(e1071))
{
print("You are missing the package 'e1071', we will now try to install it...")
install.packages("e1071", repos = repos_path, lib = library_path)
library(e1071)
}
if(!require(kernlab))
{
print("You are missing the package 'kernlab', we will now try to install it...")
install.packages("kernlab", repos = repos_path, lib = library_path)
library(kernlab)
}
# converts 'train' class of caret from S3 to S4
setOldClass("train")
#' Source files
source("middleman/FileManipulator.R")
source("classifier/GenericClassifier.R")
source("classifier/AnnClassifier.R")
source("classifier/BayesClassifier.R")
source("classifier/KnnClassifier.R")
source("classifier/TreeClassifier.R")
source("classifier/SvmClassifier.R")
source("preprocessor/FeatureEngineer.R")
source("preprocessor/InapRemover.R")
source("preprocessor/Normalizer.R")
source("preprocessor/DataCompressor.R")
source("mfExtractor/mf1Extractor.R")
source("mfExtractor/mf2Extractor.R")
source("optimizer/Optimizer.R")
source("evaluator/PerformanceEvaluator.R")
source("evaluator/HypothesisTester.R")
source("middleman/Expert.R")
source("classifier/Ensembler.R")
source("preprocessor/DataPrepare.R")
source("visualizer/FeatureVisualizer.R")
source("visualizer/PerformanceVisualizer.R")
source("middleman/Server.R")
source("middleman/InputParser.R")
#' Define workspace directory
mainDir       <- getwd()
subDir        <- "workspace"
workspace_dir <- file.path(mainDir, subDir)
Rscript experiment.R -e -d 'bank-additional.csv' -p 'project_name'
#' The script for running an experiment. This is the interface of automl software. It offfers the functionalities of
#' training the system, performing an experiment for a particular dataset by defining appropriate flags.
#' It sources build_script.R to set up the workspace. <br> <br> <br>
#' Ensure that .libpaths of Rscript.exe and R.exe agree
if(length(.libPaths()) == 1){
# We're in Rscript.exe
possible_lib_paths <- file.path(Sys.getenv(c('USERPROFILE','R_USER')),
"R","win-library",
paste(R.version$major,
substr(R.version$minor,1,1),
sep='.'))
indx <- which(file.exists(possible_lib_paths))
if(length(indx)){
.libPaths(possible_lib_paths[indx[1]])
}
# CLEAN UP
rm(indx,possible_lib_paths)
}
#' Set up workspace
source("build_script.R")
#' Load user's configuration
#' Define command-line options
option_list <- list(
make_option( c("-d", "--dataset"), type = "character",
default = "baboon_mating.csv", help = "dataset file name",
metavar = "character"),
make_option( c("-p", "--project"), type = "character", help = "name of new project",
default = NULL, metavar = "character"),
make_option( c("-w", "--workspace"), type = "character",
default = workspace_dir, help = "name of workspace directory",
metavar = "character"),
make_option( c("-t", "--train"), action = "store_true", dest = "train"),
make_option( c("-e", "--experiment"), action = "store_false", dest = "train"),
make_option( c("-c", "--compare"), action = "store_true", dest = "compare", default = FALSE)
);
opt_parser <- OptionParser(option_list=option_list);
opt        <- parse_args(opt_parser);
#' Call InputParser
inputparser <- new('InputParser')
inputparser$parseCommand(options = opt)
#' Ensure that .libpaths of Rscript.exe and R.exe agree
if(length(.libPaths()) == 1){
# We're in Rscript.exe
possible_lib_paths <- file.path(Sys.getenv(c('USERPROFILE','R_USER')),
"R","win-library",
paste(R.version$major,
substr(R.version$minor,1,1),
sep='.'))
indx <- which(file.exists(possible_lib_paths))
if(length(indx)){
.libPaths(possible_lib_paths[indx[1]])
}
# CLEAN UP
rm(indx,possible_lib_paths)
}
#' Set up workspace
source("build_script.R")
#' Define command-line options
option_list <- list(
make_option( c("-d", "--dataset"), type = "character",
default = "baboon_mating.csv", help = "dataset file name",
metavar = "character"),
make_option( c("-p", "--project"), type = "character", help = "name of new project",
default = NULL, metavar = "character"),
make_option( c("-w", "--workspace"), type = "character",
default = workspace_dir, help = "name of workspace directory",
metavar = "character"),
make_option( c("-t", "--train"), action = "store_true", dest = "train"),
make_option( c("-e", "--experiment"), action = "store_false", dest = "train"),
make_option( c("-c", "--compare"), action = "store_true", dest = "compare", default = FALSE)
);
automl is a command-line tool for the automization of machine learning experiments. It is written in R. Its aim is to offer automated solutions for each step of a machine learning pipeline by employing a variety of R packages. Meta-learning has been applied for the prediction of optimal model hyper-parameters and heuristics have been embedded in order to insert expert-like behavior to preprocessing and evaluation techniques. We are currently dealing with binary classification problems, for which we produce an optimized ensemble using the forward-model selection technique. The interface of our program aims at offering a highly customizable data scientist with an easily understandable and reusable output. To this end, a report describing the conducted experiment is created upon completion.
This is a project developed for linux-gnu using R version 3.3. All package dependencies are installed under a project-specific 'lib' directory.
experiment.R is the interface to the project. Your R working directory must be automl to run it. Script build_script.R is used to source all files and install all required packages.
Run
Rscript experiment.R -e -d 'dataset_name.csv' -p 'project_name'
to experiment with a dataset (which must be placed under workspace/datasets_repo). A directory project_'project_name' will be created under workspace, containing the experiment's output.
Available datasets for testing our program can be found under https://drive.google.com/open?id=0B5kUY54Gc5R1TkJUQWJ1V3Uzcnc. Please unzip this folder under workspace.
#' A script that sets up automl's workspace. It installs missing packages and sources the files.
#' Run with `source("build_script.R")` from automl directory. <br> <br> <br>
#' Install and load missing  packages
library_path <- "lib"
.libPaths(c( .libPaths(),library_path))
dir.create(library_path,showWarnings = FALSE)
repos_path <- "http://cran.rstudio.com/"
if(!require(nnet))
{
print("You are missing the package 'nnet', we will now try to install it...")
install.packages("nnet", repos = repos_path, lib = library_path)
library(nnet)
}
if(!require(ROCR))
{
print("You are missing the package 'ROCR', we will now try to install it...")
install.packages("ROCR", repos = repos_path, lib = library_path)
library(ROCR)
}
#' The script for running an experiment. This is the interface of automl software. It offfers the functionalities of
#' training the system, performing an experiment for a particular dataset by defining appropriate flags.
#' It sources build_script.R to set up the workspace. <br> <br> <br>
#' Ensure that .libpaths of Rscript.exe and R.exe agree
if(length(.libPaths()) == 1){
# We're in Rscript.exe
possible_lib_paths <- file.path(Sys.getenv(c('USERPROFILE','R_USER')),
"R","win-library",
paste(R.version$major,
substr(R.version$minor,1,1),
sep='.'))
indx <- which(file.exists(possible_lib_paths))
if(length(indx)){
.libPaths(possible_lib_paths[indx[1]])
}
# CLEAN UP
rm(indx,possible_lib_paths)
}
#' Set up workspace
source("build_script.R")
#' Load user's configuration
#' Define command-line options
option_list <- list(
make_option( c("-d", "--dataset"), type = "character",
default = "baboon_mating.csv", help = "dataset file name",
metavar = "character"),
make_option( c("-p", "--project"), type = "character", help = "name of new project",
default = NULL, metavar = "character"),
make_option( c("-w", "--workspace"), type = "character",
default = workspace_dir, help = "name of workspace directory",
metavar = "character"),
make_option( c("-t", "--train"), action = "store_true", dest = "train"),
make_option( c("-e", "--experiment"), action = "store_false", dest = "train"),
make_option( c("-c", "--compare"), action = "store_true", dest = "compare", default = FALSE)
);
opt_parser <- OptionParser(option_list=option_list);
opt        <- parse_args(opt_parser);
#' Call InputParser
inputparser <- new('InputParser')
inputparser$parseCommand(options = opt)
load("/home/elena/thesis_ws/automl/workspace/project_bank-additional/experiment_info2.Rdata")
load("/project_bank-additional/experiment_info2.Rdata")
load("/christina/Documents/GitHub/automl/workspace/project_bank-additional/experiment_info2.Rdata")
load("~/GitHub/automl/workspace/project_bank-additional/experiment_info.Rdata")
View(data)
View(data)
sayHello()
sayHello <- function(){
print('hello')
}
sayHello()
args = commandArgs(trailingOnly=TRUE)
Rscript --vanilla sillyScript.R iris.txt out.txt
Rscript --vanilla sillyScript.R iris.txt
library("ROCR", lib.loc="~/lib")
detach("package:ROCR", unload=TRUE)
remove.packages("ROCR", lib="~/lib")
install.packages("ROCR")
opt_parser <- OptionParser(option_list=option_list);
View(sayHello)
#' Set up workspace
source("build_script.R")
#' Ensure that .libpaths of Rscript.exe and R.exe agree
if(length(.libPaths()) == 1){
# We're in Rscript.exe
possible_lib_paths <- file.path(Sys.getenv(c('USERPROFILE','R_USER')),
"R","win-library",
paste(R.version$major,
substr(R.version$minor,1,1),
sep='.'))
indx <- which(file.exists(possible_lib_paths))
if(length(indx)){
.libPaths(possible_lib_paths[indx[1]])
}
# CLEAN UP
rm(indx,possible_lib_paths)
}
#' Set up workspace
source("build_script.R")
opt_parser <- OptionParser(option_list=option_list);
##  --- set up ---
rm(list=ls())
setwd("/Users/christina/Documents/GitHub/ads-h2o")
source("build_script.R")
##  --- generate testing metafeatures ---
repo       <-"/Users/christina/Dropbox/AutoML/Datasets/Classification/dataset-name/processed"
files_list <- list.files(path = repo,  pattern="*.csv", recursive = TRUE)
for(i in seq(1, length(files_list))) {
dataset_path <- files_list[[i]]
dataset      <- read.csv(paste(repo, dataset_path, sep = "/"),
header = TRUE, sep=",", stringsAsFactors=FALSE)
dataset_name <- substr(dataset_path,1,nchar(dataset_path)-4)
variables    <- names(dataset[sapply(dataset,class) == "character"])
dataset[, (names(dataset) %in% variables)] <- lapply(as.data.frame(dataset[, (names(dataset) %in% variables)]),
as.factor)
file_manipulator <- FileManipulator$new()
data_prepare     <- DataPrepare$new()
dictionary       <- file_manipulator$loadOrderedDictionary()
dataset          <- data_prepare$convertAttributeTypes(dataset, dictionary)
expert           <- Expert$new()
dataset          <- expert$choosePreprocessing(dataset=dataset, task = list(inf_action=NA, inf_replace= NA,
unknown_action=NA, unknown_replace = NA
,normalize = NA, compress = NA))
mf1_extractor    <- new('mf1Extractor')
mf2_extractor    <- new('mf2Extractor', mf1_extractor_ = mf1_extractor)
meta2features_me <- mf2_extractor$get2MetaFeatures(dataset = dataset)
if(i == 1 ) {
total_metafeatures <- meta2features_me
} else {
total_metafeatures <- rbind(total_metafeatures,meta2features_me)
}
}
##  --- generate testing metafeatures ---
repo       <-"/Users/christina/Desktop/trainning datasets/training"
files_list <- list.files(path = repo,  pattern="*.csv", recursive = TRUE)
files_list
s = data.frame(files_list)
View(s)
View(s)
write.csv(s, "./thesis_experiments/readiness_metric/nhsiwth.csv")
# This script generates training metafeatures.
##  --- set up ---
rm(list=ls())
setwd("/Users/christina/Documents/GitHub/ads-h2o")
source("build_script.R")
##  --- generate testing metafeatures ---
repo       <-"/Users/christina/Dropbox/AutoML/Datasets/Classification/dataset-name/processed"
files_list <- list.files(path = repo,  pattern="*.csv", recursive = TRUE)
for(i in seq(1, length(files_list))) {
dataset_path <- files_list[[i]]
dataset      <- read.csv(paste(repo, dataset_path, sep = "/"),
header = TRUE, sep=",", stringsAsFactors=FALSE)
dataset_name <- substr(dataset_path,1,nchar(dataset_path)-4)
variables    <- names(dataset[sapply(dataset,class) == "character"])
dataset[, (names(dataset) %in% variables)] <- lapply(as.data.frame(dataset[, (names(dataset) %in% variables)]),
as.factor)
file_manipulator <- FileManipulator$new()
data_prepare     <- DataPrepare$new()
dictionary       <- file_manipulator$loadOrderedDictionary()
dataset          <- data_prepare$convertAttributeTypes(dataset, dictionary)
expert           <- Expert$new()
dataset          <- expert$choosePreprocessing(dataset=dataset, task = list(inf_action=NA, inf_replace= NA,
unknown_action=NA, unknown_replace = NA
,normalize = NA, compress = NA))
mf1_extractor    <- new('mf1Extractor')
mf2_extractor    <- new('mf2Extractor', mf1_extractor_ = mf1_extractor)
meta2features_me <- mf2_extractor$get2MetaFeatures(dataset = dataset)
if(i == 1 ) {
total_metafeatures <- meta2features_me
} else {
total_metafeatures <- rbind(total_metafeatures,meta2features_me)
}
}
rownames(total_metafeatures) <- files_list
write.csv(total_metafeatures, "./thesis_experiments/readiness_metric/training_metafeatures.csv")
