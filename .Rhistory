# We're in Rscript.exe
possible_lib_paths <- file.path(Sys.getenv(c('USERPROFILE','R_USER')),
"R","win-library",
paste(R.version$major,
substr(R.version$minor,1,1),
sep='.'))
indx <- which(file.exists(possible_lib_paths))
if(length(indx)){
.libPaths(possible_lib_paths[indx[1]])
}
# CLEAN UP
rm(indx,possible_lib_paths)
}
#' Set up workspace
source("build_script.R")
#' Load user's configuration
#' Define command-line options
option_list <- list(
make_option( c("-d", "--dataset"), type = "character",
default = "baboon_mating.csv", help = "dataset file name",
metavar = "character"),
make_option( c("-p", "--project"), type = "character", help = "name of new project",
default = NULL, metavar = "character"),
make_option( c("-w", "--workspace"), type = "character",
default = workspace_dir, help = "name of workspace directory",
metavar = "character"),
make_option( c("-t", "--train"), action = "store_true", dest = "train"),
make_option( c("-e", "--experiment"), action = "store_false", dest = "train"),
make_option( c("-c", "--compare"), action = "store_true", dest = "compare", default = FALSE)
);
opt_parser <- OptionParser(option_list=option_list);
opt        <- parse_args(opt_parser);
#' Call InputParser
inputparser <- new('InputParser')
inputparser$parseCommand(options = opt)
#' Ensure that .libpaths of Rscript.exe and R.exe agree
if(length(.libPaths()) == 1){
# We're in Rscript.exe
possible_lib_paths <- file.path(Sys.getenv(c('USERPROFILE','R_USER')),
"R","win-library",
paste(R.version$major,
substr(R.version$minor,1,1),
sep='.'))
indx <- which(file.exists(possible_lib_paths))
if(length(indx)){
.libPaths(possible_lib_paths[indx[1]])
}
# CLEAN UP
rm(indx,possible_lib_paths)
}
#' Set up workspace
source("build_script.R")
#' Define command-line options
option_list <- list(
make_option( c("-d", "--dataset"), type = "character",
default = "baboon_mating.csv", help = "dataset file name",
metavar = "character"),
make_option( c("-p", "--project"), type = "character", help = "name of new project",
default = NULL, metavar = "character"),
make_option( c("-w", "--workspace"), type = "character",
default = workspace_dir, help = "name of workspace directory",
metavar = "character"),
make_option( c("-t", "--train"), action = "store_true", dest = "train"),
make_option( c("-e", "--experiment"), action = "store_false", dest = "train"),
make_option( c("-c", "--compare"), action = "store_true", dest = "compare", default = FALSE)
);
automl is a command-line tool for the automization of machine learning experiments. It is written in R. Its aim is to offer automated solutions for each step of a machine learning pipeline by employing a variety of R packages. Meta-learning has been applied for the prediction of optimal model hyper-parameters and heuristics have been embedded in order to insert expert-like behavior to preprocessing and evaluation techniques. We are currently dealing with binary classification problems, for which we produce an optimized ensemble using the forward-model selection technique. The interface of our program aims at offering a highly customizable data scientist with an easily understandable and reusable output. To this end, a report describing the conducted experiment is created upon completion.
This is a project developed for linux-gnu using R version 3.3. All package dependencies are installed under a project-specific 'lib' directory.
experiment.R is the interface to the project. Your R working directory must be automl to run it. Script build_script.R is used to source all files and install all required packages.
Run
Rscript experiment.R -e -d 'dataset_name.csv' -p 'project_name'
to experiment with a dataset (which must be placed under workspace/datasets_repo). A directory project_'project_name' will be created under workspace, containing the experiment's output.
Available datasets for testing our program can be found under https://drive.google.com/open?id=0B5kUY54Gc5R1TkJUQWJ1V3Uzcnc. Please unzip this folder under workspace.
#' A script that sets up automl's workspace. It installs missing packages and sources the files.
#' Run with `source("build_script.R")` from automl directory. <br> <br> <br>
#' Install and load missing  packages
library_path <- "lib"
.libPaths(c( .libPaths(),library_path))
dir.create(library_path,showWarnings = FALSE)
repos_path <- "http://cran.rstudio.com/"
if(!require(nnet))
{
print("You are missing the package 'nnet', we will now try to install it...")
install.packages("nnet", repos = repos_path, lib = library_path)
library(nnet)
}
if(!require(ROCR))
{
print("You are missing the package 'ROCR', we will now try to install it...")
install.packages("ROCR", repos = repos_path, lib = library_path)
library(ROCR)
}
#' The script for running an experiment. This is the interface of automl software. It offfers the functionalities of
#' training the system, performing an experiment for a particular dataset by defining appropriate flags.
#' It sources build_script.R to set up the workspace. <br> <br> <br>
#' Ensure that .libpaths of Rscript.exe and R.exe agree
if(length(.libPaths()) == 1){
# We're in Rscript.exe
possible_lib_paths <- file.path(Sys.getenv(c('USERPROFILE','R_USER')),
"R","win-library",
paste(R.version$major,
substr(R.version$minor,1,1),
sep='.'))
indx <- which(file.exists(possible_lib_paths))
if(length(indx)){
.libPaths(possible_lib_paths[indx[1]])
}
# CLEAN UP
rm(indx,possible_lib_paths)
}
#' Set up workspace
source("build_script.R")
#' Load user's configuration
#' Define command-line options
option_list <- list(
make_option( c("-d", "--dataset"), type = "character",
default = "baboon_mating.csv", help = "dataset file name",
metavar = "character"),
make_option( c("-p", "--project"), type = "character", help = "name of new project",
default = NULL, metavar = "character"),
make_option( c("-w", "--workspace"), type = "character",
default = workspace_dir, help = "name of workspace directory",
metavar = "character"),
make_option( c("-t", "--train"), action = "store_true", dest = "train"),
make_option( c("-e", "--experiment"), action = "store_false", dest = "train"),
make_option( c("-c", "--compare"), action = "store_true", dest = "compare", default = FALSE)
);
opt_parser <- OptionParser(option_list=option_list);
opt        <- parse_args(opt_parser);
#' Call InputParser
inputparser <- new('InputParser')
inputparser$parseCommand(options = opt)
load("/home/elena/thesis_ws/automl/workspace/project_bank-additional/experiment_info2.Rdata")
load("/project_bank-additional/experiment_info2.Rdata")
load("/christina/Documents/GitHub/automl/workspace/project_bank-additional/experiment_info2.Rdata")
load("~/GitHub/automl/workspace/project_bank-additional/experiment_info.Rdata")
View(data)
View(data)
sayHello()
sayHello <- function(){
print('hello')
}
sayHello()
args = commandArgs(trailingOnly=TRUE)
Rscript --vanilla sillyScript.R iris.txt out.txt
Rscript --vanilla sillyScript.R iris.txt
library("ROCR", lib.loc="~/lib")
detach("package:ROCR", unload=TRUE)
remove.packages("ROCR", lib="~/lib")
install.packages("ROCR")
opt_parser <- OptionParser(option_list=option_list);
View(sayHello)
#' Set up workspace
source("build_script.R")
#' Ensure that .libpaths of Rscript.exe and R.exe agree
if(length(.libPaths()) == 1){
# We're in Rscript.exe
possible_lib_paths <- file.path(Sys.getenv(c('USERPROFILE','R_USER')),
"R","win-library",
paste(R.version$major,
substr(R.version$minor,1,1),
sep='.'))
indx <- which(file.exists(possible_lib_paths))
if(length(indx)){
.libPaths(possible_lib_paths[indx[1]])
}
# CLEAN UP
rm(indx,possible_lib_paths)
}
#' Set up workspace
source("build_script.R")
opt_parser <- OptionParser(option_list=option_list);
install.packages("RSiteCatalyst", type = "source")
install.packages("RSiteCatalyst")
library(RSiteCatalyst)
key <- "username:company>"
secret <- "https://sc.omniture.com/p/suite/1.3/index.html?a=User.GetAccountInfo >"
SCAuth(key, secret)
## --- example1 ---- Retrieving Adobe SiteCatalyst data with R ----
dailyStats <- QueueOvertime(my.rsid,
date.from = "2016-01-01",
date.to = "2016-06-30",
metrics = c("pageviews","visits"),
date.granularity = "day"
)
library(RSiteCatalyst)
SCAuth("username:company", "cd1d234dee56e8202da6f7d3213eb1ef")
library(RSiteCatalyst)
SCAuth("username:company", "cd1d234dee56e8202da6f7d3213eb1ef")
GetReportSuites()
key <- "username:company>"
secret <- "https://sc.omniture.com/p/suite/1.3/index.html?a=User.GetAccountInfo >"
SCAuth(key, secret)
## --- example1 ---- Retrieving Adobe SiteCatalyst data with R ----
dailyStats <- QueueOvertime(my.rsid,
date.from = "2016-01-01",
date.to = "2016-06-30",
metrics = c("pageviews","visits"),
date.granularity = "day"
)
library("RSiteCatalyst")
library("d3Network")
install.packages("d3Network")
library("d3Network")
#### Authentication
SCAuth("username", "secret")
#### Get Pathing data using ::anything:: wildcards
# Results are limited by the API to 50000
pathpattern <- c("::anything::", "::anything::")
queue_pathing_pages <- QueuePathing("zwitchdev",
"2014-01-01",
"2014-08-31",
metric="pageviews",
element="page",
pathpattern,
top = 50000)
#Optional step: Cleaning my pagename URLs to remove to domain for graph clarity
queue_pathing_pages$step.1 <- sub("http://randyzwitch.com/","",
queue_pathing_pages$step.1, ignore.case = TRUE)
queue_pathing_pages$step.2 <- sub("http://randyzwitch.com/","",
queue_pathing_pages$step.2, ignore.case = TRUE)
#### Remove Enter and Exit site values
#This information is important for analysis, but not related to website structure
graph_links <- subset(queue_pathing_pages, step.1 != "Entered Site" & step.2 != "Exited Site")
#### First pass - Simple Network
# Setting standAlone = TRUE creates a full HTML file to view graph
# Set equal to FALSE to just get the d3 JavaScript
simpleoutput1 = "C:/Users/rzwitc200/Desktop/simpleoutput1.html"
d3SimpleNetwork(graph_links, Source = "step.1", Target = "step.2", height = 600,
width = 750, fontsize = 12, linkDistance = 50, charge = -50,
linkColour = "#666", nodeColour = "#3182bd",
nodeClickColour = "#E34A33", textColour = "#3182bd", opacity = 0.6,
standAlone = TRUE, file = simpleoutput1)
##  --- set up ---
rm(list=ls())
setwd("C:/Users/christina/Documents/GitHub/ads-h2o")
source("build_script.R")
##  --- set up ---
rm(list=ls())
setwd("C:/Users/christina/Documents/GitHub/ads-h2o")
##  --- generate testing metafeatures ---
repo       <-"C:/Users/christina/Dropbox/AutoML/Datasets/Classification/dataset-name/processed"
files_list <- list.files(path = repo,  pattern="*.csv", recursive = TRUE)
i=1
dataset_path <- files_list[[i]]
dataset      <- read.csv(paste(repo, dataset_path, sep = "/"),
header = TRUE, sep=",", stringsAsFactors=FALSE)
r = length(unique(dataset$Class))
Num_class = length(unique(dataset$Class))
roes = nrow(dataset)
rows = nrow(dataset)
dataset_path <- files_list[[i]]
dataset      <- read.csv(paste(repo, dataset_path, sep = "/"),
header = TRUE, sep=",", stringsAsFactors=FALSE)
dataset_name <- substr(dataset_path,1,nchar(dataset_path)-4)
variables    <- names(dataset[sapply(dataset,class) == "character"])
dataset[, (names(dataset) %in% variables)] <- lapply(as.data.frame(dataset[, (names(dataset) %in% variables)]),
as.factor)
file_manipulator <- FileManipulator$new()
dataset
file_manipulator <- FileManipulator$new()
data_prepare     <- DataPrepare$new()
dictionary       <- file_manipulator$loadOrderedDictionary()
dataset          <- data_prepare$convertAttributeTypes(dataset, dictionary)
artibutes =
f <- sapply(dataset, is.factor)
f
columns
##  --- set up ---
rm(list=ls())
setwd("C:/Users/christina/Documents/GitHub/ads-h2o")
##  --- generate testing metafeatures ---
repo       <-"C:/Users/christina/Dropbox/AutoML/Datasets/Classification/dataset-name/processed"
files_list <- list.files(path = repo,  pattern="*.csv", recursive = TRUE)
i=1
dataset_path <- files_list[[i]]
dataset      <- read.csv(paste(repo, dataset_path, sep = "/"),
header = TRUE, sep=",", stringsAsFactors=FALSE)
dataset_name <- substr(dataset_path,1,nchar(dataset_path)-4)
Num_class = length(unique(dataset$Class))
rows = nrow(dataset)
columns = ncol(dataset)
artibutes =
f <- sapply(dataset, is.factor)
factor_chk = f[which(f,f==TRUE)]
chk =0
f <- sapply(dataset, is.factor)
for (i in 1:columns){
if (f[i]==TRUE)
chk = 1
}
f
f[i]
View(dataset)
chk_n = 0
f <- sapply(dataset, is.factor)
for (i in 1:columns){
if (f[i]==TRUE)
chk_f = 1
}
chk_f =0
chk_n = 0
f <- sapply(dataset, is.factor)
for (i in 1:columns){
if (f[i]==TRUE){
chk_f = 1
}
if (f[i]==FALSE)
chk_n = 1
}
chk_n
if(chk_f==1){
artibutes = "Categorical"
}else if(chk_n==1){
artibutes = "Numeric"
}else if ( chk_f ==1 & chk_n ==1){
artibutes = "Categorical, Numeric"
}
artibutes
files_list <- list.files(path = repo,  pattern="*.csv", recursive = TRUE)
for(i in 1:length(files_list)) {
dataset_path <- files_list[[i]]
dataset      <- read.csv(paste(repo, dataset_path, sep = "/"),
header = TRUE, sep=",", stringsAsFactors=FALSE)
dataset_name <- substr(dataset_path,1,nchar(dataset_path)-4)
Num_class = length(unique(dataset$Class))
rows = nrow(dataset)
columns = ncol(dataset)
chk_f =0
chk_n = 0
f <- sapply(dataset, is.factor)
for (i in 1:columns){
if (f[i]==TRUE){
chk_f = 1
}
if (f[i]==FALSE)
chk_n = 1
}
if(chk_f==1){
artibutes = "Categorical"
}else if(chk_n==1){
artibutes = "Numeric"
}else if ( chk_f ==1 & chk_n ==1){
artibutes = "Categorical, Numeric"
}
info <- cbind(dataset_name,rows,columns,artibutes,Num_class)
if(i == 1 ) {
total_metafeatures <- info
} else {
total_metafeatures <- rbind(total_metafeatures,info)
}
}
# This script generates training and testing metafeatures.
##  --- set up ---
rm(list=ls())
setwd("C:/Users/christina/Documents/GitHub/ads-h2o")
##  --- generate testing metafeatures ---
repo       <-"C:/Users/christina/Dropbox/AutoML/Datasets/Classification/dataset-name/processed"
files_list <- list.files(path = repo,  pattern="*.csv", recursive = TRUE)
for(i in 1:length(files_list)) {
dataset_path <- files_list[[i]]
dataset      <- read.csv(paste(repo, dataset_path, sep = "/"),
header = TRUE, sep=",", stringsAsFactors=FALSE)
dataset_name <- substr(dataset_path,1,nchar(dataset_path)-4)
Num_class = length(unique(dataset$Class))
rows = nrow(dataset)
columns = ncol(dataset)
chk_f =0
chk_n = 0
f <- sapply(dataset, is.factor)
for (i in 1:columns){
if (f[i]==TRUE){
chk_f = 1
}
if (f[i]==FALSE)
chk_n = 1
}
if(chk_f==1){
artibutes = "Categorical"
}else if(chk_n==1){
artibutes = "Numeric"
}else if ( chk_f ==1 & chk_n ==1){
artibutes = "Categorical, Numeric"
}
info <- cbind(dataset_name,rows,columns,artibutes,Num_class)
if(i == 1 ) {
info_total <- info
} else {
info_total <- rbind(info_total,info)
}
}
i
##  --- set up ---
rm(list=ls())
setwd("C:/Users/christina/Documents/GitHub/ads-h2o")
##  --- generate testing metafeatures ---
repo       <-"C:/Users/christina/Dropbox/AutoML/Datasets/Classification/dataset-name/processed"
files_list <- list.files(path = repo,  pattern="*.csv", recursive = TRUE)
for(i in 1:length(files_list)) {
dataset_path <- files_list[[i]]
dataset      <- read.csv(paste(repo, dataset_path, sep = "/"),
header = TRUE, sep=",", stringsAsFactors=FALSE)
dataset_name <- substr(dataset_path,1,nchar(dataset_path)-4)
Num_class = length(unique(dataset$Class))
rows = nrow(dataset)
columns = ncol(dataset)
chk_f =0
chk_n = 0
f <- sapply(dataset, is.factor)
for (i in 1:columns){
if (f[i]==TRUE){
chk_f = 1
}
if (f[i]==FALSE)
chk_n = 1
}
if(chk_f==1){
artibutes = "Categorical"
}else if(chk_n==1){
artibutes = "Numeric"
}else if ( chk_f ==1 & chk_n ==1){
artibutes = "Categorical, Numeric"
}
info <- cbind(dataset_name,rows,columns,artibutes,Num_class)
if(i == 1 ) {
info_total <- info
} else {
info_total <- rbind(info_total,info)
}
}
##  --- set up ---
rm(list=ls())
setwd("C:/Users/christina/Documents/GitHub/ads-h2o")
##  --- generate testing metafeatures ---
repo       <-"C:/Users/christina/Dropbox/AutoML/Datasets/Classification/dataset-name/processed"
files_list <- list.files(path = repo,  pattern="*.csv", recursive = TRUE)
i=1
dataset_path <- files_list[[i]]
dataset      <- read.csv(paste(repo, dataset_path, sep = "/"),
header = TRUE, sep=",", stringsAsFactors=FALSE)
dataset_name <- substr(dataset_path,1,nchar(dataset_path)-4)
Num_class = length(unique(dataset$Class))
rows = nrow(dataset)
columns = ncol(dataset)
chk_f =0
chk_n = 0
f <- sapply(dataset, is.factor)
for (i in 1:columns){
if (f[i]==TRUE){
chk_f = 1
}
if (f[i]==FALSE)
chk_n = 1
}
if(chk_f==1){
artibutes = "Categorical"
}else if(chk_n==1){
artibutes = "Numeric"
}else if ( chk_f ==1 & chk_n ==1){
artibutes = "Categorical, Numeric"
}
info <- cbind(dataset_name,rows,columns,artibutes,Num_class)
if(i == 1 ) {
info_total <- info
} else {
info_total <- rbind(info_total,info)
}
info_total
(i == 1 )
i
##  --- set up ---
rm(list=ls())
setwd("C:/Users/christina/Documents/GitHub/ads-h2o")
##  --- generate testing metafeatures ---
repo       <-"C:/Users/christina/Dropbox/AutoML/Datasets/Classification/dataset-name/processed"
files_list <- list.files(path = repo,  pattern="*.csv", recursive = TRUE)
for(i in 1:length(files_list)) {
dataset_path <- files_list[[i]]
dataset      <- read.csv(paste(repo, dataset_path, sep = "/"),
header = TRUE, sep=",", stringsAsFactors=FALSE)
dataset_name <- substr(dataset_path,1,nchar(dataset_path)-4)
Num_class = length(unique(dataset$Class))
rows = nrow(dataset)
columns = ncol(dataset)
chk_f =0
chk_n = 0
f <- sapply(dataset, is.factor)
for (k in 1:columns){
if (f[k]==TRUE){
chk_f = 1
}
if (f[k]==FALSE)
chk_n = 1
}
if(chk_f==1){
artibutes = "Categorical"
}else if(chk_n==1){
artibutes = "Numeric"
}else if ( chk_f ==1 & chk_n ==1){
artibutes = "Categorical, Numeric"
}
info <- cbind(dataset_name,rows,columns,artibutes,Num_class)
if(i == 1 ) {
info_total <- info
} else {
info_total <- rbind(info_total,info)
}
}
dataset_path <- files_list[[i]]
write.csv(total_metafeatures, "info.csv")
write.csv(total_info, "info.csv")
write.csv(info_total, "info.csv")
